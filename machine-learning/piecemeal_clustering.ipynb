{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecemeal Clustering\n",
    "A clustering approach without prior knowledge about data even number of clusters. It uses similarity and density of data to define number of clusters. \n",
    "\n",
    "### Reading the Paper\n",
    "#### Introduction\n",
    "- No noise: KMeans, SOM\n",
    "- Density-based: DBSCAN\n",
    "- Precedents: trial and errors, combinations of multiple methods\n",
    "- What is lithofaces, \n",
    "- The algorithm utilizes the density-based clustering combining the concepts of hierachical clustering, model-based unsupervised learning and density-based data clustering. \n",
    "\n",
    "### Reference:\n",
    "- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9980364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from scipy.cluster import hierarchy as sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (150, 4)\n",
      "Shape of y: (150,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cluster(clusters, i, j):\n",
    "    for t in range(len(clusters)):\n",
    "        if clusters[t] == j:\n",
    "            clusters[t] = clusters[i]\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ind_to_pair(d, index):\n",
    "    b = 1 - (2 * d) \n",
    "    i = (-b - np.sqrt(b ** 2 - 8 * index)) // 2\n",
    "    j = index + i * (b + i + 2) // 2 + 1\n",
    "    return (int(i), int(j))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist_threshold(dmatrix, cutoff: float):\n",
    "    dmin = min(dmatrix)\n",
    "    dmax = max(dmatrix)\n",
    "    return (1 - (dmin / dmax)) * cutoff\n",
    "\n",
    "def compute_sim_threshold(smatrix, cutoff: float, diff_factor: float):\n",
    "    dmin = min(smatrix)\n",
    "    dmax = max(smatrix)\n",
    "    return (1 - (dmin / dmax)) * cutoff * diff_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_distances(dmatrix, smatrix, diff_factor: float):\n",
    "    dmax = max(dmatrix)\n",
    "    smax = max(smatrix)\n",
    "\n",
    "    dmatrix = dmatrix / dmax\n",
    "    dmatrix = dmatrix ** 2\n",
    "    smatrix = smatrix / smax\n",
    "    smatrix = diff_factor * (smatrix**2)\n",
    "\n",
    "    return np.sqrt(dmatrix + smatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum distance: 0.15074813431681336\n"
     ]
    }
   ],
   "source": [
    "def pre_clustering(X, cutoff: float, diff_factor: float):\n",
    "    dmatrix = sch.distance.pdist(X, metric=\"euclidean\")\n",
    "    smatrix = sch.distance.pdist(X, metric=\"cosine\")\n",
    "    clusters = np.arange(0, len(X), 1)\n",
    "    dt = compute_dist_threshold(dmatrix, cutoff)\n",
    "    st = compute_sim_threshold(smatrix, cutoff, diff_factor)\n",
    "    tds = np.sqrt(dt**2 + st**2)\n",
    "    cd = compute_cluster_distances(dmatrix, smatrix, diff_factor)\n",
    "    dim = len(X)\n",
    "\n",
    "    print(f\"Minimum distance: {tds}\")\n",
    "    sorted_cd = np.argsort(cd)\n",
    "    \n",
    "    for index in sorted_cd:\n",
    "        d = cd[index]\n",
    "        i, j = ind_to_pair(dim, index)\n",
    "        if d <= tds:\n",
    "            merge_cluster(clusters, i, j)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "clusters = pre_clustering(X, 0.015, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_center_mapping(names, X, y):\n",
    "    data = np.column_stack((names, X, y))\n",
    "    df = pd.DataFrame(data, columns=[\"cluster\", \"x1\", \"x2\", \"x3\", \"x4\", \"y\"])\n",
    "    df[\"cluster\"] = df[\"cluster\"].astype(int)\n",
    "\n",
    "    df1 = df.groupby(by=[\"cluster\"])[[\"x1\", \"x2\", \"x3\", \"x4\"]].mean().sort_index()\n",
    "    df2 = df.groupby(by=[\"cluster\"])[\"y\"].agg(pd.Series.mode).sort_index()\n",
    "    return df1.to_numpy(), df2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers, cluster_mapping = compute_cluster_center_mapping(clusters, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Cluster Centers: (5, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Cluster Centers: {cluster_centers.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_decay(step, N):\n",
    "    return 1 - (step / N)\n",
    "\n",
    "def compute_radii(W):\n",
    "    dmatrix = sch.distance.pdist(W, metric=\"euclidean\")\n",
    "    smatrix = sch.distance.pdist(W, metric=\"cosine\")\n",
    "    radius_d = (max(dmatrix) - min(dmatrix)) / 2\n",
    "    radius_s = (max(smatrix) - min(smatrix)) / 2\n",
    "    return radius_d, radius_s\n",
    "\n",
    "def unit_distances(x, W):\n",
    "    x = x.reshape(1, -1)\n",
    "    W = W.copy()\n",
    "    d = np.sqrt(np.sum((x - W)**2, axis=1))\n",
    "    x = x / np.linalg.norm(x, axis=1)\n",
    "    W = W.T / np.linalg.norm(W, axis=1)\n",
    "    ### Same method as pdist\n",
    "    s = 1 - x.dot(W)\n",
    "    return d, s.reshape(-1)\n",
    "\n",
    "def train_som(X, W, N, alpha_0):\n",
    "    \"\"\"This is the modifed version of training Self-organizing map\n",
    "    Args:\n",
    "    - X: input data shape (m, n)\n",
    "    - W: weight matrix, in piecemeal, the weight matrix is the cluster centers\n",
    "    - alpha_0: learning rate\n",
    "    - N: number of iterations\n",
    "    \"\"\"\n",
    "    W = W.copy()\n",
    "    n_neurals = len(W)\n",
    "    n_samples = len(X)\n",
    "    print(f\"Number of neurals: {n_neurals}\")\n",
    "    rd_0, rs_0 = compute_radii(W)\n",
    "    for step in range(N):\n",
    "        rd = rd_0 * compute_decay(step, N)\n",
    "        rs = rs_0 * compute_decay(step, N)\n",
    "        alpha = alpha_0 * compute_decay(step, N)\n",
    "\n",
    "        x = X[np.random.choice(n_samples)]\n",
    "        ud, us = unit_distances(x, W)\n",
    "        for i, (cd, cs) in enumerate(zip(ud, us)):\n",
    "            if cd < rd and cs < rs:\n",
    "                i_d = np.exp((-cd**2) / (2*rd**2))\n",
    "                i_s = np.exp((-cs**2) / (2*rs**2))\n",
    "                influence = np.sqrt(i_d * i_s)\n",
    "                W[i] += alpha * influence * (x - W[i])\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.006     , 3.428     , 1.462     , 0.246     ],\n",
       "       [6.36101695, 2.92542373, 5.05254237, 1.79830508],\n",
       "       [5.53214286, 2.63571429, 3.96071429, 1.22857143],\n",
       "       [6.3       , 3.3       , 6.        , 2.5       ],\n",
       "       [7.475     , 3.125     , 6.3       , 2.05      ]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurals: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.99974208, 3.42323295, 1.46683226, 0.24634987],\n",
       "       [6.21259188, 2.88096088, 4.85312563, 1.66848272],\n",
       "       [5.9417436 , 2.78130169, 4.46797915, 1.46189966],\n",
       "       [6.39307002, 3.00715134, 5.30348633, 1.9480127 ],\n",
       "       [6.80656279, 3.02795585, 5.61259458, 1.9681041 ]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_som(X, cluster_centers, 10000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
